{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing is a programming method that **harnesses the power of multiple processors (or cores) at once**. Once of concern only to programmers of large supercomputers, modern computers now almost always have multi-core processors. However:\n",
    "\n",
    "> At the heart of efficient parallel code is fast serial code!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many CPU cores do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Hwloc\n",
    "Hwloc.num_physical_cores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that `Sys.CPU_THREADS` may or may not be equal to the number above. It indicates the number of CPUs + Hyperthreads.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why go parallel?\n",
    "\n",
    "<img src=\"imgs/42-years-processor-trend.svg\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Amdahl's Law**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive expectation: I have 4 cores, give me my 4x speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">If $p$ is the fraction of a code that can be parallelized than the maximal theoretical speedup by parallelizing on $n$ cores is given by $F(n) = 1/(1-p + p/n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip410\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip410)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip411\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip410)\" d=\"\n",
       "M201.232 1423.18 L2352.76 1423.18 L2352.76 47.2441 L201.232 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip412\">\n",
       "    <rect x=\"201\" y=\"47\" width=\"2153\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  532.756,1423.18 532.756,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  938.704,1423.18 938.704,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1344.65,1423.18 1344.65,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1750.6,1423.18 1750.6,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.55,1423.18 2156.55,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,47.2441 2352.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  532.756,1423.18 532.756,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  938.704,1423.18 938.704,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1344.65,1423.18 1344.65,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1750.6,1423.18 1750.6,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.55,1423.18 2156.55,1404.28 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M537.004 1466.95 Q540.36 1467.66 542.235 1469.93 Q544.133 1472.2 544.133 1475.53 Q544.133 1480.65 540.615 1483.45 Q537.096 1486.25 530.615 1486.25 Q528.439 1486.25 526.124 1485.81 Q523.833 1485.39 521.379 1484.54 L521.379 1480.02 Q523.323 1481.16 525.638 1481.74 Q527.953 1482.32 530.476 1482.32 Q534.874 1482.32 537.166 1480.58 Q539.481 1478.84 539.481 1475.53 Q539.481 1472.48 537.328 1470.77 Q535.198 1469.03 531.379 1469.03 L527.351 1469.03 L527.351 1465.19 L531.564 1465.19 Q535.013 1465.19 536.842 1463.82 Q538.671 1462.43 538.671 1459.84 Q538.671 1457.18 536.772 1455.77 Q534.897 1454.33 531.379 1454.33 Q529.458 1454.33 527.259 1454.75 Q525.059 1455.16 522.421 1456.04 L522.421 1451.88 Q525.083 1451.14 527.397 1450.77 Q529.735 1450.39 531.796 1450.39 Q537.12 1450.39 540.221 1452.83 Q543.323 1455.23 543.323 1459.35 Q543.323 1462.22 541.68 1464.21 Q540.036 1466.18 537.004 1466.95 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M939.109 1466.44 Q935.961 1466.44 934.109 1468.59 Q932.281 1470.74 932.281 1474.49 Q932.281 1478.22 934.109 1480.39 Q935.961 1482.55 939.109 1482.55 Q942.257 1482.55 944.086 1480.39 Q945.938 1478.22 945.938 1474.49 Q945.938 1470.74 944.086 1468.59 Q942.257 1466.44 939.109 1466.44 M948.392 1451.78 L948.392 1456.04 Q946.632 1455.21 944.827 1454.77 Q943.044 1454.33 941.285 1454.33 Q936.656 1454.33 934.202 1457.45 Q931.771 1460.58 931.424 1466.9 Q932.79 1464.89 934.85 1463.82 Q936.91 1462.73 939.387 1462.73 Q944.595 1462.73 947.605 1465.9 Q950.637 1469.05 950.637 1474.49 Q950.637 1479.82 947.489 1483.03 Q944.341 1486.25 939.109 1486.25 Q933.114 1486.25 929.943 1481.67 Q926.771 1477.06 926.771 1468.33 Q926.771 1460.14 930.66 1455.28 Q934.549 1450.39 941.1 1450.39 Q942.859 1450.39 944.642 1450.74 Q946.447 1451.09 948.392 1451.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1334.95 1484.86 L1334.95 1480.6 Q1336.71 1481.44 1338.52 1481.88 Q1340.32 1482.32 1342.06 1482.32 Q1346.69 1482.32 1349.12 1479.21 Q1351.57 1476.09 1351.92 1469.75 Q1350.58 1471.74 1348.52 1472.8 Q1346.46 1473.87 1343.96 1473.87 Q1338.77 1473.87 1335.74 1470.74 Q1332.73 1467.59 1332.73 1462.15 Q1332.73 1456.83 1335.88 1453.61 Q1339.03 1450.39 1344.26 1450.39 Q1350.25 1450.39 1353.4 1455 Q1356.57 1459.58 1356.57 1468.33 Q1356.57 1476.51 1352.68 1481.39 Q1348.82 1486.25 1342.27 1486.25 Q1340.51 1486.25 1338.7 1485.9 Q1336.9 1485.56 1334.95 1484.86 M1344.26 1470.21 Q1347.41 1470.21 1349.24 1468.06 Q1351.09 1465.9 1351.09 1462.15 Q1351.09 1458.43 1349.24 1456.27 Q1347.41 1454.1 1344.26 1454.1 Q1341.11 1454.1 1339.26 1456.27 Q1337.43 1458.43 1337.43 1462.15 Q1337.43 1465.9 1339.26 1468.06 Q1341.11 1470.21 1344.26 1470.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1726.09 1481.64 L1733.72 1481.64 L1733.72 1455.28 L1725.41 1456.95 L1725.41 1452.69 L1733.68 1451.02 L1738.35 1451.02 L1738.35 1481.64 L1745.99 1481.64 L1745.99 1485.58 L1726.09 1485.58 L1726.09 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1759.47 1481.64 L1775.78 1481.64 L1775.78 1485.58 L1753.84 1485.58 L1753.84 1481.64 Q1756.5 1478.89 1761.09 1474.26 Q1765.69 1469.61 1766.87 1468.27 Q1769.12 1465.74 1770 1464.01 Q1770.9 1462.25 1770.9 1460.56 Q1770.9 1457.8 1768.96 1456.07 Q1767.03 1454.33 1763.93 1454.33 Q1761.73 1454.33 1759.28 1455.09 Q1756.85 1455.86 1754.07 1457.41 L1754.07 1452.69 Q1756.9 1451.55 1759.35 1450.97 Q1761.8 1450.39 1763.84 1450.39 Q1769.21 1450.39 1772.41 1453.08 Q1775.6 1455.77 1775.6 1460.26 Q1775.6 1462.39 1774.79 1464.31 Q1774 1466.2 1771.9 1468.8 Q1771.32 1469.47 1768.22 1472.69 Q1765.11 1475.88 1759.47 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M2131.73 1481.64 L2139.37 1481.64 L2139.37 1455.28 L2131.06 1456.95 L2131.06 1452.69 L2139.33 1451.02 L2144 1451.02 L2144 1481.64 L2151.64 1481.64 L2151.64 1485.58 L2131.73 1485.58 L2131.73 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M2161.13 1451.02 L2179.49 1451.02 L2179.49 1454.96 L2165.41 1454.96 L2165.41 1463.43 Q2166.43 1463.08 2167.45 1462.92 Q2168.47 1462.73 2169.49 1462.73 Q2175.27 1462.73 2178.65 1465.9 Q2182.03 1469.08 2182.03 1474.49 Q2182.03 1480.07 2178.56 1483.17 Q2175.09 1486.25 2168.77 1486.25 Q2166.59 1486.25 2164.33 1485.88 Q2162.08 1485.51 2159.67 1484.77 L2159.67 1480.07 Q2161.76 1481.2 2163.98 1481.76 Q2166.2 1482.32 2168.68 1482.32 Q2172.68 1482.32 2175.02 1480.21 Q2177.36 1478.1 2177.36 1474.49 Q2177.36 1470.88 2175.02 1468.77 Q2172.68 1466.67 2168.68 1466.67 Q2166.8 1466.67 2164.93 1467.08 Q2163.08 1467.5 2161.13 1468.38 L2161.13 1451.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1044.49 1546.53 L1044.49 1568.04 L1038.63 1568.04 L1038.63 1546.72 Q1038.63 1541.66 1036.66 1539.14 Q1034.68 1536.63 1030.74 1536.63 Q1025.99 1536.63 1023.26 1539.65 Q1020.52 1542.68 1020.52 1547.9 L1020.52 1568.04 L1014.63 1568.04 L1014.63 1532.4 L1020.52 1532.4 L1020.52 1537.93 Q1022.62 1534.72 1025.45 1533.13 Q1028.32 1531.54 1032.04 1531.54 Q1038.18 1531.54 1041.34 1535.36 Q1044.49 1539.14 1044.49 1546.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1055.56 1553.98 L1055.56 1532.4 L1061.42 1532.4 L1061.42 1553.75 Q1061.42 1558.81 1063.39 1561.36 Q1065.37 1563.87 1069.31 1563.87 Q1074.06 1563.87 1076.79 1560.85 Q1079.56 1557.83 1079.56 1552.61 L1079.56 1532.4 L1085.42 1532.4 L1085.42 1568.04 L1079.56 1568.04 L1079.56 1562.57 Q1077.43 1565.82 1074.6 1567.41 Q1071.8 1568.97 1068.07 1568.97 Q1061.93 1568.97 1058.75 1565.15 Q1055.56 1561.33 1055.56 1553.98 M1070.3 1531.54 L1070.3 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1125.24 1539.24 Q1127.43 1535.29 1130.49 1533.41 Q1133.54 1531.54 1137.68 1531.54 Q1143.25 1531.54 1146.27 1535.45 Q1149.3 1539.33 1149.3 1546.53 L1149.3 1568.04 L1143.41 1568.04 L1143.41 1546.72 Q1143.41 1541.59 1141.6 1539.11 Q1139.78 1536.63 1136.06 1536.63 Q1131.51 1536.63 1128.86 1539.65 Q1126.22 1542.68 1126.22 1547.9 L1126.22 1568.04 L1120.33 1568.04 L1120.33 1546.72 Q1120.33 1541.56 1118.52 1539.11 Q1116.71 1536.63 1112.92 1536.63 Q1108.43 1536.63 1105.79 1539.68 Q1103.15 1542.71 1103.15 1547.9 L1103.15 1568.04 L1097.26 1568.04 L1097.26 1532.4 L1103.15 1532.4 L1103.15 1537.93 Q1105.15 1534.66 1107.95 1533.1 Q1110.75 1531.54 1114.6 1531.54 Q1118.49 1531.54 1121.19 1533.51 Q1123.93 1535.48 1125.24 1539.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1186.57 1550.25 Q1186.57 1543.79 1183.9 1540.13 Q1181.25 1536.44 1176.61 1536.44 Q1171.96 1536.44 1169.29 1540.13 Q1166.64 1543.79 1166.64 1550.25 Q1166.64 1556.71 1169.29 1560.4 Q1171.96 1564.07 1176.61 1564.07 Q1181.25 1564.07 1183.9 1560.4 Q1186.57 1556.71 1186.57 1550.25 M1166.64 1537.81 Q1168.49 1534.62 1171.29 1533.1 Q1174.12 1531.54 1178.04 1531.54 Q1184.53 1531.54 1188.57 1536.69 Q1192.65 1541.85 1192.65 1550.25 Q1192.65 1558.65 1188.57 1563.81 Q1184.53 1568.97 1178.04 1568.97 Q1174.12 1568.97 1171.29 1567.44 Q1168.49 1565.88 1166.64 1562.7 L1166.64 1568.04 L1160.76 1568.04 L1160.76 1518.52 L1166.64 1518.52 L1166.64 1537.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1232.85 1548.76 L1232.85 1551.62 L1205.92 1551.62 Q1206.3 1557.67 1209.55 1560.85 Q1212.83 1564 1218.65 1564 Q1222.03 1564 1225.18 1563.17 Q1228.36 1562.35 1231.48 1560.69 L1231.48 1566.23 Q1228.33 1567.57 1225.02 1568.27 Q1221.71 1568.97 1218.3 1568.97 Q1209.77 1568.97 1204.78 1564 Q1199.81 1559.04 1199.81 1550.57 Q1199.81 1541.82 1204.52 1536.69 Q1209.26 1531.54 1217.28 1531.54 Q1224.48 1531.54 1228.65 1536.18 Q1232.85 1540.8 1232.85 1548.76 M1226.99 1547.04 Q1226.93 1542.23 1224.29 1539.37 Q1221.68 1536.5 1217.35 1536.5 Q1212.45 1536.5 1209.49 1539.27 Q1206.56 1542.04 1206.11 1547.07 L1226.99 1547.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1263.12 1537.87 Q1262.13 1537.3 1260.95 1537.04 Q1259.81 1536.76 1258.41 1536.76 Q1253.44 1536.76 1250.77 1540 Q1248.13 1543.22 1248.13 1549.27 L1248.13 1568.04 L1242.24 1568.04 L1242.24 1532.4 L1248.13 1532.4 L1248.13 1537.93 Q1249.97 1534.69 1252.93 1533.13 Q1255.89 1531.54 1260.12 1531.54 Q1260.73 1531.54 1261.46 1531.63 Q1262.19 1531.7 1263.08 1531.85 L1263.12 1537.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1303.79 1536.5 Q1299.08 1536.5 1296.35 1540.19 Q1293.61 1543.85 1293.61 1550.25 Q1293.61 1556.65 1296.31 1560.34 Q1299.05 1564 1303.79 1564 Q1308.47 1564 1311.21 1560.31 Q1313.95 1556.62 1313.95 1550.25 Q1313.95 1543.92 1311.21 1540.23 Q1308.47 1536.5 1303.79 1536.5 M1303.79 1531.54 Q1311.43 1531.54 1315.79 1536.5 Q1320.15 1541.47 1320.15 1550.25 Q1320.15 1559 1315.79 1564 Q1311.43 1568.97 1303.79 1568.97 Q1296.12 1568.97 1291.76 1564 Q1287.43 1559 1287.43 1550.25 Q1287.43 1541.47 1291.76 1536.5 Q1296.12 1531.54 1303.79 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1347.91 1518.52 L1347.91 1523.39 L1342.31 1523.39 Q1339.16 1523.39 1337.91 1524.66 Q1336.7 1525.93 1336.7 1529.24 L1336.7 1532.4 L1346.35 1532.4 L1346.35 1536.95 L1336.7 1536.95 L1336.7 1568.04 L1330.82 1568.04 L1330.82 1536.95 L1325.21 1536.95 L1325.21 1532.4 L1330.82 1532.4 L1330.82 1529.91 Q1330.82 1523.96 1333.59 1521.26 Q1336.35 1518.52 1342.37 1518.52 L1347.91 1518.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1399.18 1533.76 L1399.18 1539.24 Q1396.7 1537.87 1394.19 1537.2 Q1391.7 1536.5 1389.16 1536.5 Q1383.46 1536.5 1380.31 1540.13 Q1377.16 1543.73 1377.16 1550.25 Q1377.16 1556.78 1380.31 1560.4 Q1383.46 1564 1389.16 1564 Q1391.7 1564 1394.19 1563.33 Q1396.7 1562.63 1399.18 1561.26 L1399.18 1566.68 Q1396.73 1567.82 1394.09 1568.39 Q1391.48 1568.97 1388.52 1568.97 Q1380.47 1568.97 1375.73 1563.91 Q1370.98 1558.85 1370.98 1550.25 Q1370.98 1541.53 1375.76 1536.53 Q1380.56 1531.54 1388.9 1531.54 Q1391.61 1531.54 1394.19 1532.11 Q1396.76 1532.65 1399.18 1533.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1423.18 1536.5 Q1418.47 1536.5 1415.73 1540.19 Q1413 1543.85 1413 1550.25 Q1413 1556.65 1415.7 1560.34 Q1418.44 1564 1423.18 1564 Q1427.86 1564 1430.6 1560.31 Q1433.34 1556.62 1433.34 1550.25 Q1433.34 1543.92 1430.6 1540.23 Q1427.86 1536.5 1423.18 1536.5 M1423.18 1531.54 Q1430.82 1531.54 1435.18 1536.5 Q1439.54 1541.47 1439.54 1550.25 Q1439.54 1559 1435.18 1564 Q1430.82 1568.97 1423.18 1568.97 Q1415.51 1568.97 1411.15 1564 Q1406.82 1559 1406.82 1550.25 Q1406.82 1541.47 1411.15 1536.5 Q1415.51 1531.54 1423.18 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1469.91 1537.87 Q1468.92 1537.3 1467.74 1537.04 Q1466.6 1536.76 1465.2 1536.76 Q1460.23 1536.76 1457.56 1540 Q1454.92 1543.22 1454.92 1549.27 L1454.92 1568.04 L1449.03 1568.04 L1449.03 1532.4 L1454.92 1532.4 L1454.92 1537.93 Q1456.76 1534.69 1459.72 1533.13 Q1462.68 1531.54 1466.91 1531.54 Q1467.52 1531.54 1468.25 1531.63 Q1468.98 1531.7 1469.87 1531.85 L1469.91 1537.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1505.11 1548.76 L1505.11 1551.62 L1478.18 1551.62 Q1478.56 1557.67 1481.81 1560.85 Q1485.09 1564 1490.91 1564 Q1494.29 1564 1497.44 1563.17 Q1500.62 1562.35 1503.74 1560.69 L1503.74 1566.23 Q1500.59 1567.57 1497.28 1568.27 Q1493.97 1568.97 1490.56 1568.97 Q1482.03 1568.97 1477.04 1564 Q1472.07 1559.04 1472.07 1550.57 Q1472.07 1541.82 1476.78 1536.69 Q1481.52 1531.54 1489.54 1531.54 Q1496.74 1531.54 1500.91 1536.18 Q1505.11 1540.8 1505.11 1548.76 M1499.25 1547.04 Q1499.19 1542.23 1496.55 1539.37 Q1493.94 1536.5 1489.61 1536.5 Q1484.71 1536.5 1481.75 1539.27 Q1478.82 1542.04 1478.37 1547.07 L1499.25 1547.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M1537.45 1533.45 L1537.45 1538.98 Q1534.96 1537.71 1532.29 1537.07 Q1529.62 1536.44 1526.75 1536.44 Q1522.39 1536.44 1520.2 1537.77 Q1518.03 1539.11 1518.03 1541.79 Q1518.03 1543.82 1519.59 1545 Q1521.15 1546.15 1525.86 1547.2 L1527.87 1547.64 Q1534.1 1548.98 1536.71 1551.43 Q1539.36 1553.85 1539.36 1558.21 Q1539.36 1563.17 1535.41 1566.07 Q1531.49 1568.97 1524.62 1568.97 Q1521.76 1568.97 1518.64 1568.39 Q1515.55 1567.85 1512.11 1566.74 L1512.11 1560.69 Q1515.36 1562.38 1518.51 1563.24 Q1521.66 1564.07 1524.75 1564.07 Q1528.89 1564.07 1531.11 1562.66 Q1533.34 1561.23 1533.34 1558.65 Q1533.34 1556.27 1531.72 1554.99 Q1530.13 1553.72 1524.68 1552.54 L1522.65 1552.07 Q1517.2 1550.92 1514.78 1548.56 Q1512.37 1546.18 1512.37 1542.04 Q1512.37 1537.01 1515.93 1534.27 Q1519.5 1531.54 1526.05 1531.54 Q1529.3 1531.54 1532.16 1532.01 Q1535.03 1532.49 1537.45 1533.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.232,1211.16 2352.76,1211.16 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.232,951.554 2352.76,951.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.232,691.944 2352.76,691.944 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.232,432.333 2352.76,432.333 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  201.232,172.723 2352.76,172.723 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,1423.18 201.232,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2352.76,1423.18 2352.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,1211.16 220.13,1211.16 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,951.554 220.13,951.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,691.944 220.13,691.944 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,432.333 220.13,432.333 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  201.232,172.723 220.13,172.723 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M158.103 1209.81 Q161.459 1210.53 163.334 1212.8 Q165.232 1215.07 165.232 1218.4 Q165.232 1223.51 161.714 1226.31 Q158.195 1229.12 151.714 1229.12 Q149.538 1229.12 147.223 1228.68 Q144.931 1228.26 142.478 1227.4 L142.478 1222.89 Q144.422 1224.02 146.737 1224.6 Q149.052 1225.18 151.575 1225.18 Q155.973 1225.18 158.265 1223.44 Q160.579 1221.71 160.579 1218.4 Q160.579 1215.34 158.427 1213.63 Q156.297 1211.89 152.478 1211.89 L148.45 1211.89 L148.45 1208.05 L152.663 1208.05 Q156.112 1208.05 157.94 1206.69 Q159.769 1205.3 159.769 1202.7 Q159.769 1200.04 157.871 1198.63 Q155.996 1197.19 152.478 1197.19 Q150.556 1197.19 148.357 1197.61 Q146.158 1198.03 143.519 1198.91 L143.519 1194.74 Q146.181 1194 148.496 1193.63 Q150.834 1193.26 152.894 1193.26 Q158.218 1193.26 161.32 1195.69 Q164.422 1198.1 164.422 1202.22 Q164.422 1205.09 162.778 1207.08 Q161.135 1209.05 158.103 1209.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M153.704 949.691 Q150.556 949.691 148.704 951.843 Q146.876 953.996 146.876 957.746 Q146.876 961.473 148.704 963.649 Q150.556 965.802 153.704 965.802 Q156.853 965.802 158.681 963.649 Q160.533 961.473 160.533 957.746 Q160.533 953.996 158.681 951.843 Q156.853 949.691 153.704 949.691 M162.987 935.038 L162.987 939.297 Q161.227 938.464 159.422 938.024 Q157.64 937.584 155.88 937.584 Q151.251 937.584 148.797 940.709 Q146.366 943.834 146.019 950.154 Q147.385 948.14 149.445 947.075 Q151.505 945.987 153.982 945.987 Q159.19 945.987 162.2 949.158 Q165.232 952.306 165.232 957.746 Q165.232 963.07 162.084 966.288 Q158.936 969.505 153.704 969.505 Q147.709 969.505 144.538 964.922 Q141.366 960.316 141.366 951.589 Q141.366 943.394 145.255 938.533 Q149.144 933.649 155.695 933.649 Q157.454 933.649 159.237 933.996 Q161.042 934.344 162.987 935.038 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M143.612 708.506 L143.612 704.247 Q145.371 705.08 147.177 705.52 Q148.982 705.96 150.718 705.96 Q155.348 705.96 157.778 702.858 Q160.232 699.733 160.579 693.39 Q159.237 695.381 157.177 696.446 Q155.116 697.511 152.616 697.511 Q147.431 697.511 144.399 694.386 Q141.39 691.238 141.39 685.798 Q141.39 680.474 144.538 677.256 Q147.686 674.039 152.917 674.039 Q158.913 674.039 162.061 678.645 Q165.232 683.228 165.232 691.978 Q165.232 700.15 161.343 705.034 Q157.478 709.895 150.927 709.895 Q149.167 709.895 147.362 709.548 Q145.556 709.2 143.612 708.506 M152.917 693.853 Q156.065 693.853 157.894 691.7 Q159.746 689.548 159.746 685.798 Q159.746 682.071 157.894 679.918 Q156.065 677.742 152.917 677.742 Q149.769 677.742 147.917 679.918 Q146.089 682.071 146.089 685.798 Q146.089 689.548 147.917 691.7 Q149.769 693.853 152.917 693.853 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M115.533 445.678 L123.172 445.678 L123.172 419.312 L114.862 420.979 L114.862 416.72 L123.126 415.053 L127.802 415.053 L127.802 445.678 L135.441 445.678 L135.441 449.613 L115.533 449.613 L115.533 445.678 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M148.913 445.678 L165.232 445.678 L165.232 449.613 L143.288 449.613 L143.288 445.678 Q145.95 442.923 150.533 438.294 Q155.14 433.641 156.32 432.298 Q158.565 429.775 159.445 428.039 Q160.348 426.28 160.348 424.59 Q160.348 421.835 158.403 420.099 Q156.482 418.363 153.38 418.363 Q151.181 418.363 148.728 419.127 Q146.297 419.891 143.519 421.442 L143.519 416.72 Q146.343 415.585 148.797 415.007 Q151.251 414.428 153.288 414.428 Q158.658 414.428 161.852 417.113 Q165.047 419.798 165.047 424.289 Q165.047 426.419 164.237 428.34 Q163.45 430.238 161.343 432.831 Q160.765 433.502 157.663 436.72 Q154.561 439.914 148.913 445.678 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M114.931 186.067 L122.57 186.067 L122.57 159.702 L114.26 161.368 L114.26 157.109 L122.524 155.443 L127.2 155.443 L127.2 186.067 L134.839 186.067 L134.839 190.003 L114.931 190.003 L114.931 186.067 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M144.329 155.443 L162.686 155.443 L162.686 159.378 L148.612 159.378 L148.612 167.85 Q149.63 167.503 150.649 167.341 Q151.667 167.155 152.686 167.155 Q158.473 167.155 161.852 170.327 Q165.232 173.498 165.232 178.915 Q165.232 184.493 161.76 187.595 Q158.288 190.674 151.968 190.674 Q149.792 190.674 147.524 190.303 Q145.279 189.933 142.871 189.192 L142.871 184.493 Q144.954 185.628 147.177 186.183 Q149.399 186.739 151.876 186.739 Q155.88 186.739 158.218 184.632 Q160.556 182.526 160.556 178.915 Q160.556 175.304 158.218 173.197 Q155.88 171.091 151.876 171.091 Q150.001 171.091 148.126 171.507 Q146.274 171.924 144.329 172.804 L144.329 155.443 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M58.657 995.999 L77.5631 995.999 L77.5631 1001.89 L28.3562 1001.89 L28.3562 995.999 L33.7671 995.999 Q30.5842 994.153 29.0564 991.352 Q27.4968 988.519 27.4968 984.604 Q27.4968 978.111 32.6531 974.069 Q37.8093 969.995 46.212 969.995 Q54.6147 969.995 59.771 974.069 Q64.9272 978.111 64.9272 984.604 Q64.9272 988.519 63.3994 991.352 Q61.8398 994.153 58.657 995.999 M46.212 976.074 Q39.7508 976.074 36.0905 978.748 Q32.3984 981.39 32.3984 986.037 Q32.3984 990.684 36.0905 993.357 Q39.7508 995.999 46.212 995.999 Q52.6732 995.999 56.3653 993.357 Q60.0256 990.684 60.0256 986.037 Q60.0256 981.39 56.3653 978.748 Q52.6732 976.074 46.212 976.074 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M46.0847 944.087 Q46.0847 951.184 47.7079 953.922 Q49.3312 956.659 53.2461 956.659 Q56.3653 956.659 58.2114 954.622 Q60.0256 952.553 60.0256 949.02 Q60.0256 944.15 56.5881 941.222 Q53.1188 938.262 47.3897 938.262 L46.0847 938.262 L46.0847 944.087 M43.6657 932.406 L64.0042 932.406 L64.0042 938.262 L58.5933 938.262 Q61.8398 940.267 63.3994 943.259 Q64.9272 946.251 64.9272 950.58 Q64.9272 956.054 61.8716 959.301 Q58.7843 962.515 53.6281 962.515 Q47.6125 962.515 44.5569 958.505 Q41.5014 954.463 41.5014 946.474 L41.5014 938.262 L40.9285 938.262 Q36.8862 938.262 34.6901 940.936 Q32.4621 943.577 32.4621 948.384 Q32.4621 951.439 33.1941 954.336 Q33.9262 957.232 35.3903 959.905 L29.9795 959.905 Q28.7381 956.691 28.1334 953.667 Q27.4968 950.643 27.4968 947.779 Q27.4968 940.044 31.5072 936.225 Q35.5176 932.406 43.6657 932.406 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M33.8307 899.686 Q33.2578 900.673 33.0032 901.85 Q32.7167 902.996 32.7167 904.397 Q32.7167 909.362 35.9632 912.035 Q39.1779 914.677 45.2253 914.677 L64.0042 914.677 L64.0042 920.565 L28.3562 920.565 L28.3562 914.677 L33.8944 914.677 Q30.6479 912.831 29.0883 909.871 Q27.4968 906.911 27.4968 902.678 Q27.4968 902.073 27.5923 901.341 Q27.656 900.609 27.8151 899.718 L33.8307 899.686 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M46.0847 877.342 Q46.0847 884.44 47.7079 887.177 Q49.3312 889.915 53.2461 889.915 Q56.3653 889.915 58.2114 887.878 Q60.0256 885.809 60.0256 882.276 Q60.0256 877.406 56.5881 874.478 Q53.1188 871.518 47.3897 871.518 L46.0847 871.518 L46.0847 877.342 M43.6657 865.661 L64.0042 865.661 L64.0042 871.518 L58.5933 871.518 Q61.8398 873.523 63.3994 876.515 Q64.9272 879.507 64.9272 883.835 Q64.9272 889.31 61.8716 892.556 Q58.7843 895.771 53.6281 895.771 Q47.6125 895.771 44.5569 891.761 Q41.5014 887.718 41.5014 879.729 L41.5014 871.518 L40.9285 871.518 Q36.8862 871.518 34.6901 874.191 Q32.4621 876.833 32.4621 881.639 Q32.4621 884.695 33.1941 887.591 Q33.9262 890.487 35.3903 893.161 L29.9795 893.161 Q28.7381 889.946 28.1334 886.923 Q27.4968 883.899 27.4968 881.034 Q27.4968 873.3 31.5072 869.481 Q35.5176 865.661 43.6657 865.661 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M14.479 853.598 L14.479 847.742 L64.0042 847.742 L64.0042 853.598 L14.479 853.598 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M14.479 835.488 L14.479 829.631 L64.0042 829.631 L64.0042 835.488 L14.479 835.488 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M44.7161 786.886 L47.5806 786.886 L47.5806 813.813 Q53.6281 813.431 56.8109 810.184 Q59.9619 806.906 59.9619 801.081 Q59.9619 797.707 59.1344 794.556 Q58.3069 791.373 56.6518 788.254 L62.1899 788.254 Q63.5267 791.405 64.227 794.715 Q64.9272 798.026 64.9272 801.431 Q64.9272 809.961 59.9619 814.958 Q54.9967 819.924 46.5303 819.924 Q37.7774 819.924 32.6531 815.213 Q27.4968 810.471 27.4968 802.45 Q27.4968 795.256 32.1438 791.087 Q36.7589 786.886 44.7161 786.886 M42.9973 792.742 Q38.1912 792.806 35.3266 795.447 Q32.4621 798.057 32.4621 802.386 Q32.4621 807.288 35.2312 810.248 Q38.0002 813.176 43.0292 813.622 L42.9973 792.742 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M14.479 777.273 L14.479 771.417 L64.0042 771.417 L64.0042 777.273 L14.479 777.273 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M29.4065 715.717 L34.9447 715.717 Q33.6716 718.2 33.035 720.873 Q32.3984 723.547 32.3984 726.411 Q32.3984 730.772 33.7352 732.968 Q35.072 735.132 37.7456 735.132 Q39.7826 735.132 40.9603 733.573 Q42.1061 732.013 43.1565 727.303 L43.6021 725.297 Q44.9389 719.059 47.3897 716.449 Q49.8086 713.807 54.1691 713.807 Q59.1344 713.807 62.0308 717.754 Q64.9272 721.669 64.9272 728.544 Q64.9272 731.408 64.3543 734.528 Q63.8132 737.615 62.6992 741.053 L56.6518 741.053 Q58.3387 737.806 59.198 734.655 Q60.0256 731.504 60.0256 728.417 Q60.0256 724.279 58.6251 722.051 Q57.1929 719.823 54.6147 719.823 Q52.2276 719.823 50.9545 721.446 Q49.6813 723.038 48.5037 728.48 L48.0262 730.517 Q46.8804 735.96 44.5251 738.379 Q42.138 740.798 38.0002 740.798 Q32.9713 740.798 30.2341 737.233 Q27.4968 733.668 27.4968 727.112 Q27.4968 723.865 27.9743 721.001 Q28.4517 718.136 29.4065 715.717 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M58.657 698.816 L77.5631 698.816 L77.5631 704.704 L28.3562 704.704 L28.3562 698.816 L33.7671 698.816 Q30.5842 696.97 29.0564 694.169 Q27.4968 691.336 27.4968 687.421 Q27.4968 680.928 32.6531 676.886 Q37.8093 672.812 46.212 672.812 Q54.6147 672.812 59.771 676.886 Q64.9272 680.928 64.9272 687.421 Q64.9272 691.336 63.3994 694.169 Q61.8398 696.97 58.657 698.816 M46.212 678.891 Q39.7508 678.891 36.0905 681.565 Q32.3984 684.207 32.3984 688.854 Q32.3984 693.501 36.0905 696.174 Q39.7508 698.816 46.212 698.816 Q52.6732 698.816 56.3653 696.174 Q60.0256 693.501 60.0256 688.854 Q60.0256 684.207 56.3653 681.565 Q52.6732 678.891 46.212 678.891 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M44.7161 632.613 L47.5806 632.613 L47.5806 659.54 Q53.6281 659.158 56.8109 655.911 Q59.9619 652.633 59.9619 646.808 Q59.9619 643.434 59.1344 640.283 Q58.3069 637.101 56.6518 633.981 L62.1899 633.981 Q63.5267 637.132 64.227 640.443 Q64.9272 643.753 64.9272 647.158 Q64.9272 655.688 59.9619 660.685 Q54.9967 665.651 46.5303 665.651 Q37.7774 665.651 32.6531 660.94 Q27.4968 656.198 27.4968 648.177 Q27.4968 640.984 32.1438 636.814 Q36.7589 632.613 44.7161 632.613 M42.9973 638.469 Q38.1912 638.533 35.3266 641.175 Q32.4621 643.785 32.4621 648.113 Q32.4621 653.015 35.2312 655.975 Q38.0002 658.903 43.0292 659.349 L42.9973 638.469 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M44.7161 592.509 L47.5806 592.509 L47.5806 619.436 Q53.6281 619.054 56.8109 615.807 Q59.9619 612.529 59.9619 606.704 Q59.9619 603.33 59.1344 600.179 Q58.3069 596.997 56.6518 593.877 L62.1899 593.877 Q63.5267 597.028 64.227 600.339 Q64.9272 603.649 64.9272 607.054 Q64.9272 615.584 59.9619 620.582 Q54.9967 625.547 46.5303 625.547 Q37.7774 625.547 32.6531 620.836 Q27.4968 616.094 27.4968 608.073 Q27.4968 600.88 32.1438 596.71 Q36.7589 592.509 44.7161 592.509 M42.9973 598.365 Q38.1912 598.429 35.3266 601.071 Q32.4621 603.681 32.4621 608.009 Q32.4621 612.911 35.2312 615.871 Q38.0002 618.799 43.0292 619.245 L42.9973 598.365 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M33.7671 559.439 L14.479 559.439 L14.479 553.582 L64.0042 553.582 L64.0042 559.439 L58.657 559.439 Q61.8398 561.285 63.3994 564.118 Q64.9272 566.919 64.9272 570.865 Q64.9272 577.327 59.771 581.401 Q54.6147 585.443 46.212 585.443 Q37.8093 585.443 32.6531 581.401 Q27.4968 577.327 27.4968 570.865 Q27.4968 566.919 29.0564 564.118 Q30.5842 561.285 33.7671 559.439 M46.212 579.395 Q52.6732 579.395 56.3653 576.754 Q60.0256 574.08 60.0256 569.433 Q60.0256 564.786 56.3653 562.112 Q52.6732 559.439 46.212 559.439 Q39.7508 559.439 36.0905 562.112 Q32.3984 564.786 32.3984 569.433 Q32.3984 574.08 36.0905 576.754 Q39.7508 579.395 46.212 579.395 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M49.9359 542.124 L28.3562 542.124 L28.3562 536.268 L49.7131 536.268 Q54.7739 536.268 57.3202 534.294 Q59.8346 532.321 59.8346 528.374 Q59.8346 523.632 56.8109 520.895 Q53.7872 518.125 48.5673 518.125 L28.3562 518.125 L28.3562 512.269 L64.0042 512.269 L64.0042 518.125 L58.5296 518.125 Q61.7762 520.258 63.3676 523.091 Q64.9272 525.892 64.9272 529.616 Q64.9272 535.758 61.1078 538.941 Q57.2883 542.124 49.9359 542.124 M27.4968 527.388 L27.4968 527.388 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M58.657 494.541 L77.5631 494.541 L77.5631 500.429 L28.3562 500.429 L28.3562 494.541 L33.7671 494.541 Q30.5842 492.694 29.0564 489.894 Q27.4968 487.061 27.4968 483.146 Q27.4968 476.653 32.6531 472.611 Q37.8093 468.537 46.212 468.537 Q54.6147 468.537 59.771 472.611 Q64.9272 476.653 64.9272 483.146 Q64.9272 487.061 63.3994 489.894 Q61.8398 492.694 58.657 494.541 M46.212 474.616 Q39.7508 474.616 36.0905 477.289 Q32.3984 479.931 32.3984 484.578 Q32.3984 489.225 36.0905 491.899 Q39.7508 494.541 46.212 494.541 Q52.6732 494.541 56.3653 491.899 Q60.0256 489.225 60.0256 484.578 Q60.0256 479.931 56.3653 477.289 Q52.6732 474.616 46.212 474.616 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip412)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1297.7 532.756,1211.16 668.072,1124.63 803.388,1038.09 938.704,951.554 1074.02,865.017 1209.34,778.48 1344.65,691.944 1479.97,605.407 \n",
       "  1615.28,518.87 1750.6,432.333 1885.92,345.796 2021.23,259.259 2156.55,172.723 2291.86,86.1857 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1305.94 532.756,1234.77 668.072,1169.78 803.388,1110.2 938.704,1055.4 1074.02,1004.81 1209.34,957.964 1344.65,914.467 1479.97,873.969 \n",
       "  1615.28,836.172 1750.6,800.812 1885.92,767.663 2021.23,736.523 2156.55,707.215 2291.86,679.581 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#3da44d; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1313.44 532.756,1254.43 668.072,1204.51 803.388,1161.71 938.704,1124.63 1074.02,1092.18 1209.34,1063.54 1344.65,1038.09 1479.97,1015.32 \n",
       "  1615.28,994.822 1750.6,976.279 1885.92,959.421 2021.23,944.029 2156.55,929.92 2291.86,916.939 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#c271d2; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1326.55 532.756,1285.34 668.072,1254.43 803.388,1230.39 938.704,1211.16 1074.02,1195.43 1209.34,1182.32 1344.65,1171.22 1479.97,1161.71 \n",
       "  1615.28,1153.47 1750.6,1146.26 1885.92,1139.9 2021.23,1134.24 2156.55,1129.18 2291.86,1124.63 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#ac8d18; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1347.15 532.756,1326.55 668.072,1313.44 803.388,1304.36 938.704,1297.7 1074.02,1292.61 1209.34,1288.59 1344.65,1285.34 1479.97,1282.65 \n",
       "  1615.28,1280.39 1750.6,1278.47 1885.92,1276.81 2021.23,1275.37 2156.55,1274.1 2291.86,1272.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#00a9ad; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1362.6 532.756,1352.77 668.072,1347.15 803.388,1343.52 938.704,1340.97 1074.02,1339.09 1209.34,1337.64 1344.65,1336.49 1479.97,1335.56 \n",
       "  1615.28,1334.79 1750.6,1334.14 1885.92,1333.58 2021.23,1333.1 2156.55,1332.68 2291.86,1332.32 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip412)\" style=\"stroke:#ed5d92; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  262.124,1384.24 397.44,1374.62 532.756,1370.92 668.072,1368.97 803.388,1367.76 938.704,1366.93 1074.02,1366.33 1209.34,1365.88 1344.65,1365.53 1479.97,1365.24 \n",
       "  1615.28,1365.01 1750.6,1364.81 1885.92,1364.65 2021.23,1364.5 2156.55,1364.38 2291.86,1364.27 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"\n",
       "M272.95 507.829 L639.715 507.829 L639.715 93.1086 L272.95 93.1086  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.95,507.829 639.715,507.829 639.715,93.1086 272.95,93.1086 272.95,507.829 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip410)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,144.949 440.29,144.949 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M464.867 158.293 L472.506 158.293 L472.506 131.928 L464.196 133.595 L464.196 129.335 L472.46 127.669 L477.136 127.669 L477.136 158.293 L484.775 158.293 L484.775 162.229 L464.867 162.229 L464.867 158.293 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M504.219 130.747 Q500.608 130.747 498.779 134.312 Q496.974 137.854 496.974 144.983 Q496.974 152.09 498.779 155.655 Q500.608 159.196 504.219 159.196 Q507.853 159.196 509.659 155.655 Q511.488 152.09 511.488 144.983 Q511.488 137.854 509.659 134.312 Q507.853 130.747 504.219 130.747 M504.219 127.044 Q510.029 127.044 513.085 131.65 Q516.163 136.233 516.163 144.983 Q516.163 153.71 513.085 158.317 Q510.029 162.9 504.219 162.9 Q498.409 162.9 495.33 158.317 Q492.275 153.71 492.275 144.983 Q492.275 136.233 495.33 131.65 Q498.409 127.044 504.219 127.044 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M534.381 130.747 Q530.77 130.747 528.941 134.312 Q527.136 137.854 527.136 144.983 Q527.136 152.09 528.941 155.655 Q530.77 159.196 534.381 159.196 Q538.015 159.196 539.821 155.655 Q541.649 152.09 541.649 144.983 Q541.649 137.854 539.821 134.312 Q538.015 130.747 534.381 130.747 M534.381 127.044 Q540.191 127.044 543.247 131.65 Q546.325 136.233 546.325 144.983 Q546.325 153.71 543.247 158.317 Q540.191 162.9 534.381 162.9 Q528.571 162.9 525.492 158.317 Q522.437 153.71 522.437 144.983 Q522.437 136.233 525.492 131.65 Q528.571 127.044 534.381 127.044 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M583.941 147.02 Q581.927 147.02 580.77 148.733 Q579.635 150.446 579.635 153.502 Q579.635 156.511 580.77 158.247 Q581.927 159.96 583.941 159.96 Q585.908 159.96 587.043 158.247 Q588.2 156.511 588.2 153.502 Q588.2 150.469 587.043 148.756 Q585.908 147.02 583.941 147.02 M583.941 144.081 Q587.598 144.081 589.751 146.627 Q591.904 149.173 591.904 153.502 Q591.904 157.83 589.728 160.377 Q587.575 162.9 583.941 162.9 Q580.237 162.9 578.084 160.377 Q575.932 157.83 575.932 153.502 Q575.932 149.15 578.084 146.627 Q580.26 144.081 583.941 144.081 M560.052 129.983 Q558.061 129.983 556.904 131.72 Q555.77 133.432 555.77 136.442 Q555.77 139.497 556.904 141.21 Q558.038 142.923 560.052 142.923 Q562.066 142.923 563.2 141.21 Q564.358 139.497 564.358 136.442 Q564.358 133.456 563.2 131.72 Q562.043 129.983 560.052 129.983 M580.955 127.044 L584.658 127.044 L563.038 162.9 L559.335 162.9 L580.955 127.044 M560.052 127.044 Q563.709 127.044 565.885 129.59 Q568.061 132.113 568.061 136.442 Q568.061 140.817 565.885 143.34 Q563.733 145.863 560.052 145.863 Q556.372 145.863 554.219 143.34 Q552.089 140.794 552.089 136.442 Q552.089 132.136 554.242 129.59 Q556.395 127.044 560.052 127.044 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip410)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,196.789 440.29,196.789 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M466.418 213.351 L466.418 209.092 Q468.178 209.925 469.983 210.365 Q471.789 210.805 473.525 210.805 Q478.154 210.805 480.585 207.703 Q483.039 204.578 483.386 198.235 Q482.043 200.226 479.983 201.291 Q477.923 202.356 475.423 202.356 Q470.238 202.356 467.205 199.231 Q464.196 196.083 464.196 190.643 Q464.196 185.319 467.344 182.101 Q470.492 178.884 475.724 178.884 Q481.719 178.884 484.867 183.49 Q488.039 188.073 488.039 196.823 Q488.039 204.995 484.15 209.879 Q480.284 214.74 473.733 214.74 Q471.974 214.74 470.168 214.393 Q468.363 214.045 466.418 213.351 M475.724 198.698 Q478.872 198.698 480.701 196.546 Q482.553 194.393 482.553 190.643 Q482.553 186.916 480.701 184.763 Q478.872 182.587 475.724 182.587 Q472.576 182.587 470.724 184.763 Q468.895 186.916 468.895 190.643 Q468.895 194.393 470.724 196.546 Q472.576 198.698 475.724 198.698 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M496.488 179.509 L514.844 179.509 L514.844 183.444 L500.77 183.444 L500.77 191.916 Q501.789 191.569 502.807 191.407 Q503.826 191.222 504.844 191.222 Q510.631 191.222 514.011 194.393 Q517.39 197.564 517.39 202.981 Q517.39 208.559 513.918 211.661 Q510.446 214.74 504.126 214.74 Q501.951 214.74 499.682 214.37 Q497.437 213.999 495.029 213.258 L495.029 208.559 Q497.113 209.694 499.335 210.249 Q501.557 210.805 504.034 210.805 Q508.038 210.805 510.376 208.698 Q512.714 206.592 512.714 202.981 Q512.714 199.37 510.376 197.263 Q508.038 195.157 504.034 195.157 Q502.159 195.157 500.284 195.573 Q498.432 195.99 496.488 196.87 L496.488 179.509 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M556.001 198.86 Q553.987 198.86 552.83 200.573 Q551.696 202.286 551.696 205.342 Q551.696 208.351 552.83 210.087 Q553.987 211.8 556.001 211.8 Q557.969 211.8 559.103 210.087 Q560.26 208.351 560.26 205.342 Q560.26 202.309 559.103 200.596 Q557.969 198.86 556.001 198.86 M556.001 195.921 Q559.659 195.921 561.811 198.467 Q563.964 201.013 563.964 205.342 Q563.964 209.67 561.788 212.217 Q559.635 214.74 556.001 214.74 Q552.298 214.74 550.145 212.217 Q547.992 209.67 547.992 205.342 Q547.992 200.99 550.145 198.467 Q552.321 195.921 556.001 195.921 M532.112 181.823 Q530.122 181.823 528.964 183.56 Q527.83 185.272 527.83 188.282 Q527.83 191.337 528.964 193.05 Q530.099 194.763 532.112 194.763 Q534.126 194.763 535.261 193.05 Q536.418 191.337 536.418 188.282 Q536.418 185.296 535.261 183.56 Q534.103 181.823 532.112 181.823 M553.015 178.884 L556.719 178.884 L535.099 214.74 L531.395 214.74 L553.015 178.884 M532.112 178.884 Q535.77 178.884 537.946 181.43 Q540.122 183.953 540.122 188.282 Q540.122 192.657 537.946 195.18 Q535.793 197.703 532.112 197.703 Q528.432 197.703 526.279 195.18 Q524.15 192.634 524.15 188.282 Q524.15 183.976 526.302 181.43 Q528.455 178.884 532.112 178.884 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip410)\" style=\"stroke:#3da44d; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,248.629 440.29,248.629 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M466.418 265.191 L466.418 260.932 Q468.178 261.765 469.983 262.205 Q471.789 262.645 473.525 262.645 Q478.154 262.645 480.585 259.543 Q483.039 256.418 483.386 250.075 Q482.043 252.066 479.983 253.131 Q477.923 254.196 475.423 254.196 Q470.238 254.196 467.205 251.071 Q464.196 247.923 464.196 242.483 Q464.196 237.159 467.344 233.941 Q470.492 230.724 475.724 230.724 Q481.719 230.724 484.867 235.33 Q488.039 239.913 488.039 248.663 Q488.039 256.835 484.15 261.719 Q480.284 266.58 473.733 266.58 Q471.974 266.58 470.168 266.233 Q468.363 265.885 466.418 265.191 M475.724 250.538 Q478.872 250.538 480.701 248.386 Q482.553 246.233 482.553 242.483 Q482.553 238.756 480.701 236.603 Q478.872 234.427 475.724 234.427 Q472.576 234.427 470.724 236.603 Q468.895 238.756 468.895 242.483 Q468.895 246.233 470.724 248.386 Q472.576 250.538 475.724 250.538 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M506.441 234.427 Q502.83 234.427 501.001 237.992 Q499.196 241.534 499.196 248.663 Q499.196 255.77 501.001 259.335 Q502.83 262.876 506.441 262.876 Q510.076 262.876 511.881 259.335 Q513.71 255.77 513.71 248.663 Q513.71 241.534 511.881 237.992 Q510.076 234.427 506.441 234.427 M506.441 230.724 Q512.251 230.724 515.307 235.33 Q518.386 239.913 518.386 248.663 Q518.386 257.39 515.307 261.997 Q512.251 266.58 506.441 266.58 Q500.631 266.58 497.552 261.997 Q494.497 257.39 494.497 248.663 Q494.497 239.913 497.552 235.33 Q500.631 230.724 506.441 230.724 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M556.001 250.7 Q553.987 250.7 552.83 252.413 Q551.696 254.126 551.696 257.182 Q551.696 260.191 552.83 261.927 Q553.987 263.64 556.001 263.64 Q557.969 263.64 559.103 261.927 Q560.26 260.191 560.26 257.182 Q560.26 254.149 559.103 252.436 Q557.969 250.7 556.001 250.7 M556.001 247.761 Q559.659 247.761 561.811 250.307 Q563.964 252.853 563.964 257.182 Q563.964 261.51 561.788 264.057 Q559.635 266.58 556.001 266.58 Q552.298 266.58 550.145 264.057 Q547.992 261.51 547.992 257.182 Q547.992 252.83 550.145 250.307 Q552.321 247.761 556.001 247.761 M532.112 233.663 Q530.122 233.663 528.964 235.4 Q527.83 237.112 527.83 240.122 Q527.83 243.177 528.964 244.89 Q530.099 246.603 532.112 246.603 Q534.126 246.603 535.261 244.89 Q536.418 243.177 536.418 240.122 Q536.418 237.136 535.261 235.4 Q534.103 233.663 532.112 233.663 M553.015 230.724 L556.719 230.724 L535.099 266.58 L531.395 266.58 L553.015 230.724 M532.112 230.724 Q535.77 230.724 537.946 233.27 Q540.122 235.793 540.122 240.122 Q540.122 244.497 537.946 247.02 Q535.793 249.543 532.112 249.543 Q528.432 249.543 526.279 247.02 Q524.15 244.474 524.15 240.122 Q524.15 235.816 526.302 233.27 Q528.455 230.724 532.112 230.724 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip410)\" style=\"stroke:#c271d2; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,300.469 440.29,300.469 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M476.048 301.337 Q472.715 301.337 470.793 303.119 Q468.895 304.901 468.895 308.026 Q468.895 311.151 470.793 312.934 Q472.715 314.716 476.048 314.716 Q479.381 314.716 481.303 312.934 Q483.224 311.128 483.224 308.026 Q483.224 304.901 481.303 303.119 Q479.404 301.337 476.048 301.337 M471.372 299.346 Q468.363 298.605 466.673 296.545 Q465.006 294.485 465.006 291.522 Q465.006 287.378 467.946 284.971 Q470.909 282.564 476.048 282.564 Q481.21 282.564 484.15 284.971 Q487.09 287.378 487.09 291.522 Q487.09 294.485 485.4 296.545 Q483.733 298.605 480.747 299.346 Q484.127 300.133 486.002 302.425 Q487.9 304.716 487.9 308.026 Q487.9 313.05 484.821 315.735 Q481.765 318.42 476.048 318.42 Q470.33 318.42 467.252 315.735 Q464.196 313.05 464.196 308.026 Q464.196 304.716 466.094 302.425 Q467.992 300.133 471.372 299.346 M469.659 291.962 Q469.659 294.647 471.326 296.152 Q473.016 297.656 476.048 297.656 Q479.057 297.656 480.747 296.152 Q482.46 294.647 482.46 291.962 Q482.46 289.277 480.747 287.772 Q479.057 286.267 476.048 286.267 Q473.016 286.267 471.326 287.772 Q469.659 289.277 469.659 291.962 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M506.21 286.267 Q502.599 286.267 500.77 289.832 Q498.964 293.374 498.964 300.503 Q498.964 307.61 500.77 311.175 Q502.599 314.716 506.21 314.716 Q509.844 314.716 511.65 311.175 Q513.478 307.61 513.478 300.503 Q513.478 293.374 511.65 289.832 Q509.844 286.267 506.21 286.267 M506.21 282.564 Q512.02 282.564 515.075 287.17 Q518.154 291.753 518.154 300.503 Q518.154 309.23 515.075 313.837 Q512.02 318.42 506.21 318.42 Q500.4 318.42 497.321 313.837 Q494.265 309.23 494.265 300.503 Q494.265 291.753 497.321 287.17 Q500.4 282.564 506.21 282.564 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M555.77 302.54 Q553.756 302.54 552.598 304.253 Q551.464 305.966 551.464 309.022 Q551.464 312.031 552.598 313.767 Q553.756 315.48 555.77 315.48 Q557.737 315.48 558.872 313.767 Q560.029 312.031 560.029 309.022 Q560.029 305.989 558.872 304.276 Q557.737 302.54 555.77 302.54 M555.77 299.601 Q559.427 299.601 561.58 302.147 Q563.733 304.693 563.733 309.022 Q563.733 313.35 561.557 315.897 Q559.404 318.42 555.77 318.42 Q552.066 318.42 549.913 315.897 Q547.76 313.35 547.76 309.022 Q547.76 304.67 549.913 302.147 Q552.089 299.601 555.77 299.601 M531.881 285.503 Q529.89 285.503 528.733 287.24 Q527.599 288.952 527.599 291.962 Q527.599 295.017 528.733 296.73 Q529.867 298.443 531.881 298.443 Q533.895 298.443 535.029 296.73 Q536.186 295.017 536.186 291.962 Q536.186 288.976 535.029 287.24 Q533.872 285.503 531.881 285.503 M552.784 282.564 L556.487 282.564 L534.867 318.42 L531.163 318.42 L552.784 282.564 M531.881 282.564 Q535.538 282.564 537.714 285.11 Q539.89 287.633 539.89 291.962 Q539.89 296.337 537.714 298.86 Q535.561 301.383 531.881 301.383 Q528.2 301.383 526.048 298.86 Q523.918 296.314 523.918 291.962 Q523.918 287.656 526.071 285.11 Q528.224 282.564 531.881 282.564 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip410)\" style=\"stroke:#ac8d18; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,352.309 440.29,352.309 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M476.534 350.445 Q473.386 350.445 471.534 352.598 Q469.705 354.751 469.705 358.501 Q469.705 362.228 471.534 364.403 Q473.386 366.556 476.534 366.556 Q479.682 366.556 481.511 364.403 Q483.363 362.228 483.363 358.501 Q483.363 354.751 481.511 352.598 Q479.682 350.445 476.534 350.445 M485.816 335.793 L485.816 340.052 Q484.057 339.218 482.252 338.779 Q480.469 338.339 478.71 338.339 Q474.08 338.339 471.627 341.464 Q469.196 344.589 468.849 350.908 Q470.215 348.894 472.275 347.829 Q474.335 346.742 476.812 346.742 Q482.02 346.742 485.029 349.913 Q488.062 353.061 488.062 358.501 Q488.062 363.825 484.914 367.042 Q481.765 370.26 476.534 370.26 Q470.539 370.26 467.367 365.677 Q464.196 361.07 464.196 352.343 Q464.196 344.149 468.085 339.288 Q471.974 334.404 478.525 334.404 Q480.284 334.404 482.066 334.751 Q483.872 335.098 485.816 335.793 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M506.117 338.107 Q502.506 338.107 500.677 341.672 Q498.872 345.214 498.872 352.343 Q498.872 359.45 500.677 363.015 Q502.506 366.556 506.117 366.556 Q509.751 366.556 511.557 363.015 Q513.386 359.45 513.386 352.343 Q513.386 345.214 511.557 341.672 Q509.751 338.107 506.117 338.107 M506.117 334.404 Q511.927 334.404 514.983 339.01 Q518.062 343.593 518.062 352.343 Q518.062 361.07 514.983 365.677 Q511.927 370.26 506.117 370.26 Q500.307 370.26 497.228 365.677 Q494.173 361.07 494.173 352.343 Q494.173 343.593 497.228 339.01 Q500.307 334.404 506.117 334.404 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M555.677 354.38 Q553.663 354.38 552.506 356.093 Q551.372 357.806 551.372 360.862 Q551.372 363.871 552.506 365.607 Q553.663 367.32 555.677 367.32 Q557.645 367.32 558.779 365.607 Q559.936 363.871 559.936 360.862 Q559.936 357.829 558.779 356.116 Q557.645 354.38 555.677 354.38 M555.677 351.441 Q559.335 351.441 561.487 353.987 Q563.64 356.533 563.64 360.862 Q563.64 365.19 561.464 367.737 Q559.311 370.26 555.677 370.26 Q551.973 370.26 549.821 367.737 Q547.668 365.19 547.668 360.862 Q547.668 356.51 549.821 353.987 Q551.997 351.441 555.677 351.441 M531.788 337.343 Q529.798 337.343 528.64 339.08 Q527.506 340.792 527.506 343.802 Q527.506 346.857 528.64 348.57 Q529.774 350.283 531.788 350.283 Q533.802 350.283 534.936 348.57 Q536.094 346.857 536.094 343.802 Q536.094 340.816 534.936 339.08 Q533.779 337.343 531.788 337.343 M552.691 334.404 L556.395 334.404 L534.774 370.26 L531.071 370.26 L552.691 334.404 M531.788 334.404 Q535.446 334.404 537.622 336.95 Q539.798 339.473 539.798 343.802 Q539.798 348.177 537.622 350.7 Q535.469 353.223 531.788 353.223 Q528.108 353.223 525.955 350.7 Q523.825 348.154 523.825 343.802 Q523.825 339.496 525.978 336.95 Q528.131 334.404 531.788 334.404 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip410)\" style=\"stroke:#00a9ad; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,404.149 440.29,404.149 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M479.798 390.943 L467.992 409.392 L479.798 409.392 L479.798 390.943 M478.571 386.869 L484.451 386.869 L484.451 409.392 L489.381 409.392 L489.381 413.281 L484.451 413.281 L484.451 421.429 L479.798 421.429 L479.798 413.281 L464.196 413.281 L464.196 408.767 L478.571 386.869 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M507.113 389.947 Q503.501 389.947 501.673 393.512 Q499.867 397.054 499.867 404.183 Q499.867 411.29 501.673 414.855 Q503.501 418.396 507.113 418.396 Q510.747 418.396 512.552 414.855 Q514.381 411.29 514.381 404.183 Q514.381 397.054 512.552 393.512 Q510.747 389.947 507.113 389.947 M507.113 386.244 Q512.923 386.244 515.978 390.85 Q519.057 395.433 519.057 404.183 Q519.057 412.91 515.978 417.517 Q512.923 422.1 507.113 422.1 Q501.302 422.1 498.224 417.517 Q495.168 412.91 495.168 404.183 Q495.168 395.433 498.224 390.85 Q501.302 386.244 507.113 386.244 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M556.672 406.22 Q554.659 406.22 553.501 407.933 Q552.367 409.646 552.367 412.702 Q552.367 415.711 553.501 417.447 Q554.659 419.16 556.672 419.16 Q558.64 419.16 559.774 417.447 Q560.932 415.711 560.932 412.702 Q560.932 409.669 559.774 407.956 Q558.64 406.22 556.672 406.22 M556.672 403.281 Q560.33 403.281 562.483 405.827 Q564.635 408.373 564.635 412.702 Q564.635 417.03 562.459 419.577 Q560.307 422.1 556.672 422.1 Q552.969 422.1 550.816 419.577 Q548.663 417.03 548.663 412.702 Q548.663 408.35 550.816 405.827 Q552.992 403.281 556.672 403.281 M532.784 389.183 Q530.793 389.183 529.636 390.92 Q528.501 392.632 528.501 395.642 Q528.501 398.697 529.636 400.41 Q530.77 402.123 532.784 402.123 Q534.798 402.123 535.932 400.41 Q537.089 398.697 537.089 395.642 Q537.089 392.656 535.932 390.92 Q534.774 389.183 532.784 389.183 M553.686 386.244 L557.39 386.244 L535.77 422.1 L532.066 422.1 L553.686 386.244 M532.784 386.244 Q536.441 386.244 538.617 388.79 Q540.793 391.313 540.793 395.642 Q540.793 400.017 538.617 402.54 Q536.464 405.063 532.784 405.063 Q529.103 405.063 526.95 402.54 Q524.821 399.994 524.821 395.642 Q524.821 391.336 526.974 388.79 Q529.126 386.244 532.784 386.244 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip410)\" style=\"stroke:#ed5d92; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  296.855,455.989 440.29,455.989 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip410)\" d=\"M469.821 469.333 L486.14 469.333 L486.14 473.269 L464.196 473.269 L464.196 469.333 Q466.858 466.579 471.441 461.949 Q476.048 457.296 477.228 455.954 Q479.474 453.431 480.353 451.695 Q481.256 449.935 481.256 448.246 Q481.256 445.491 479.312 443.755 Q477.391 442.019 474.289 442.019 Q472.09 442.019 469.636 442.783 Q467.205 443.547 464.428 445.097 L464.428 440.375 Q467.252 439.241 469.705 438.662 Q472.159 438.084 474.196 438.084 Q479.566 438.084 482.761 440.769 Q485.955 443.454 485.955 447.945 Q485.955 450.074 485.145 451.996 Q484.358 453.894 482.252 456.486 Q481.673 457.158 478.571 460.375 Q475.469 463.57 469.821 469.333 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M505.955 441.787 Q502.344 441.787 500.515 445.352 Q498.71 448.894 498.71 456.023 Q498.71 463.13 500.515 466.695 Q502.344 470.236 505.955 470.236 Q509.589 470.236 511.395 466.695 Q513.224 463.13 513.224 456.023 Q513.224 448.894 511.395 445.352 Q509.589 441.787 505.955 441.787 M505.955 438.084 Q511.765 438.084 514.821 442.69 Q517.9 447.273 517.9 456.023 Q517.9 464.75 514.821 469.357 Q511.765 473.94 505.955 473.94 Q500.145 473.94 497.066 469.357 Q494.011 464.75 494.011 456.023 Q494.011 447.273 497.066 442.69 Q500.145 438.084 505.955 438.084 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip410)\" d=\"M555.515 458.06 Q553.501 458.06 552.344 459.773 Q551.21 461.486 551.21 464.542 Q551.21 467.551 552.344 469.287 Q553.501 471 555.515 471 Q557.483 471 558.617 469.287 Q559.774 467.551 559.774 464.542 Q559.774 461.509 558.617 459.796 Q557.483 458.06 555.515 458.06 M555.515 455.121 Q559.172 455.121 561.325 457.667 Q563.478 460.213 563.478 464.542 Q563.478 468.87 561.302 471.417 Q559.149 473.94 555.515 473.94 Q551.811 473.94 549.659 471.417 Q547.506 468.87 547.506 464.542 Q547.506 460.19 549.659 457.667 Q551.835 455.121 555.515 455.121 M531.626 441.023 Q529.636 441.023 528.478 442.76 Q527.344 444.472 527.344 447.482 Q527.344 450.537 528.478 452.25 Q529.612 453.963 531.626 453.963 Q533.64 453.963 534.774 452.25 Q535.932 450.537 535.932 447.482 Q535.932 444.496 534.774 442.76 Q533.617 441.023 531.626 441.023 M552.529 438.084 L556.233 438.084 L534.612 473.94 L530.909 473.94 L552.529 438.084 M531.626 438.084 Q535.284 438.084 537.46 440.63 Q539.636 443.153 539.636 447.482 Q539.636 451.857 537.46 454.38 Q535.307 456.903 531.626 456.903 Q527.946 456.903 525.793 454.38 Q523.663 451.834 523.663 447.482 Q523.663 443.176 525.816 440.63 Q527.969 438.084 531.626 438.084 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "F(p,n) = 1/(1-p + p/n)\n",
    "\n",
    "pl = plot()\n",
    "for p in reverse(sort(vcat(0.2:0.2:1, [0.9, 0.95])))\n",
    "    plot!(pl, n -> F(p,n), 1:16, lab=\"$(Int(p*100))%\", lw=2,\n",
    "        legend=:topleft, xlab=\"number of cores\", ylab=\"parallel speedup\", frame=:box)\n",
    "end\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia documentation link: [Parallel computing](https://docs.julialang.org/en/v1/manual/parallel-computing/index.html)\n",
    "\n",
    "There are many types of parallelism, some of which are (from micro to macro)\n",
    "\n",
    "* **Instruction level parallelism**\n",
    "* **Multi-threading** (process shared memory)\n",
    "* **Multi-Core processing** (maybe system shared memory)\n",
    "* **Distributed processing** (same as above but involving multiple machines)\n",
    "\n",
    "Julia provides (more or less) native support for all of these forms of parallel processing (same order as above)\n",
    "\n",
    "* `@simd` and [SIMD.jl](https://github.com/eschnett/SIMD.jl)\n",
    "* `@threads, @spawn` (introduced in 2015)\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `SharedArray`, etc.\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `DistributedArray`, `MPI.jl` etc.\n",
    "\n",
    "With scientific computing in mind, we will mainly focus on how to distribute a process through multiple cores or machines (our thp cluster for example), that is **Multi-Core processing** and **Distributed processing**. But before we can do so, we have to learn how to control Julia's control flow through tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks (Control flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for every command to finish and run everything sequentially.\n",
    "\n",
    "Tasks are a control flow feature that allows computations to be **suspended** and resumed in a flexible manner. This feature is sometimes called by other names, such as coroutines, green or lightweight threads and cooperative multitasking.\n",
    "\n",
    "To me, the name **cooperative multitasking** is the most descriptive. Tasks are managed/scheduled by Julia and can sometimes be run in a quasi-parallel fashion.\n",
    "\n",
    "An important use case is **asynchronous I/O**, which is typically slow. Examples are\n",
    " * **multiple user input** (Why not already process some of the input?)\n",
    " * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " * **receiving calculations from worker processes** (We'll need that below!)\n",
    "\n",
    "How do we execute commands asynchronously?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@async` and `@sync`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Based on [this](https://stackoverflow.com/questions/37287020/how-and-when-to-use-async-and-sync-in-julia/37287021#37287021) stackoverflow answer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@async\n",
       "\\end{verbatim}\n",
       "Wrap an expression in a \\href{@ref}{\\texttt{Task}} and add it to the local machine's scheduler queue.\n",
       "\n",
       "Values can be interpolated into \\texttt{@async} via \\texttt{\\$}, which copies the value directly into the constructed underlying closure. This allows you to insert the \\emph{value} of a variable, isolating the asynchronous code from changes to the variable's value in the current task.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{compat}\n",
       "\n",
       "Julia 1.4\n",
       "\n",
       "Interpolating values via \\texttt{\\$} is available as of Julia 1.4.\n",
       "\n",
       "\\end{quote}\n"
      ],
      "text/markdown": [
       "```\n",
       "@async\n",
       "```\n",
       "\n",
       "Wrap an expression in a [`Task`](@ref) and add it to the local machine's scheduler queue.\n",
       "\n",
       "Values can be interpolated into `@async` via `$`, which copies the value directly into the constructed underlying closure. This allows you to insert the *value* of a variable, isolating the asynchronous code from changes to the variable's value in the current task.\n",
       "\n",
       "!!! compat \"Julia 1.4\"\n",
       "    Interpolating values via `$` is available as of Julia 1.4.\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  @async\u001b[39m\n",
       "\n",
       "  Wrap an expression in a \u001b[36mTask\u001b[39m and add it to the local machine's scheduler\n",
       "  queue.\n",
       "\n",
       "  Values can be interpolated into \u001b[36m@async\u001b[39m via \u001b[36m$\u001b[39m, which copies the value\n",
       "  directly into the constructed underlying closure. This allows you to insert\n",
       "  the \u001b[4mvalue\u001b[24m of a variable, isolating the asynchronous code from changes to the\n",
       "  variable's value in the current task.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mJulia 1.4\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  Interpolating values via \u001b[36m$\u001b[39m is available as of Julia 1.4."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that for whatever falls within its scope, Julia will start a task to then proceed to whatever comes next in the script **without waiting for the task to complete**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.001134 seconds (66 allocations: 1.688 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time sleep(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.010775 seconds (6.35 k allocations: 379.981 KiB, 92.33% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x00007fba21649b60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia allows the script to proceed (and the `@time` macro to fully execute) without waiting for the task (in this case, sleeping for two seconds) to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `@sync` macro to synchronize, that is wait for, all encapsulated tasks. (see `?@sync`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.019456 seconds (824 allocations: 49.609 KiB, 0.90% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00007fb979c4a6e0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @sync @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, here it doesn't make much sense to write `@sync @async` - we could simply drop it altogether.\n",
    "\n",
    "A better example is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.008897 seconds (1.12 k allocations: 70.578 KiB, 0.36% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00007fb979c4b0f0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @sync begin\n",
    "    @async sleep(2.0)\n",
    "    @async sleep(2.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello class!\n",
      "Today is reverse day!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    @async (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @async (sleep(1); println(\" class!\"))\n",
    "    @async print(\"Hello\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed processing: Multi-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed computing in Julia means having **multiple separate Julia instances running on different cores** on the same or different machines.\n",
    "\n",
    "Data movement and communication between processes is explicit.\n",
    "\n",
    "Let's focus on the *multi-core* case (your laptop/desktop) and save some cluster fun for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master-worker model\n",
    "\n",
    "Julia uses a *master-worker* paradigm for its native distributed parallelism.\n",
    "\n",
    "One master process coordinates all the worker processes, which perform the actual computations.\n",
    "\n",
    "By default, Julia starts with one process on one core. If this single process is all we have, than it is both the master and the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed # Loading all tools that we need for distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers() # the master is considered a worker as long as there are no real workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the number of workers, i.e. Julia processes, from within a Julia session we can use `addprocs`.\n",
    "\n",
    "Alternatively, when starting Julia from the command line, one can use the `-p` option. Example,\n",
    "\n",
    "```\n",
    "julia -p 4\n",
    "```\n",
    "\n",
    "will start Julia with 5 processes, 1 master and 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4) # I have 4 cores, so let's add 4 worker processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every process has a Julia internal `pid` (process id). The master is always 1. You can get the workers pids from `workers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 4 worker's pids aren't necessarily 2, 3, 4 and 5. Let's remove the processes and add them once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00007fb97840f3d0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers()) # rmprocs(array of pids of worker processes to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers() # only the master is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One master to rule them all - `@spawn`, `@spawnat`, `@fetch`, `@fetchfrom`, `@everywhere`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute commands and start computations on workers we can use the following macros\n",
    "\n",
    "* `@spawn`: run a command or a code block on any worker and return a `Future` to it's result. It's basically a version of `@async` for remote processes.\n",
    "* `@spawnat`: same as `@spawn` but one can choose a specific worker by providing its pid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's say we would like to generate a random matrix on one of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(6, 1, 10, ReentrantLock(nothing, Base.GenericCondition{Base.Threads.SpinLock}(Base.InvasiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), 0), nothing)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@spawn rand(2,2) # basically @async for remote process, i.e. returns immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(7, 1, 11, ReentrantLock(nothing, Base.GenericCondition{Base.Threads.SpinLock}(Base.InvasiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), 0), nothing)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = @spawn rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.873892   0.549974\n",
       " 0.0523779  0.528236"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(result) # blocks, like @sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the combination of spawning at fetching is so common, there is `@fetch` which combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.614739  0.90331\n",
       " 0.241076  0.752674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which worker did the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.362803  0.631745\n",
       " 0.384787  0.388226"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch begin\n",
    "    println(myid());\n",
    "    rand(2,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `@spawnat` and `@fetchfrom` we can delegate the work to a specific worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.868491  0.784499\n",
       " 0.368557  0.833647"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetchfrom 7 begin\n",
    "    println(myid());\n",
    "    rand(2,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` as a blocker to wait for all workers to complete their tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\tHello\n",
      "      From worker 7:\t class!\n",
      "      From worker 6:\tToday is reverse day!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    pids = workers()\n",
    "    @spawnat pids[1] (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @spawnat pids[2] (sleep(1); println(\" class!\"))\n",
    "    @spawnat pids[3] println(\"Hello\")\n",
    "end;\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we understood all that, let's delegate a *complicated* calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "On worker 9:\nUndefVarError: #complicated_calculation not defined\nStacktrace:\n  [1] \u001b[0m\u001b[1mdeserialize_datatype\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:1332\u001b[24m\u001b[39m\n  [2] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:854\u001b[24m\u001b[39m\n  [3] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\n  [4] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:861\u001b[24m\u001b[39m\n  [5] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [6] \u001b[0m\u001b[1mdeserialize_global_from_main\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mclusterserialize.jl:160\u001b[24m\u001b[39m\n  [7] \u001b[0m\u001b[1m#5\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mclusterserialize.jl:72\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [8] \u001b[0m\u001b[1mforeach\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2712\u001b[24m\u001b[39m\n  [9] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mclusterserialize.jl:72\u001b[24m\u001b[39m\n [10] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:947\u001b[24m\u001b[39m\n [11] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\n [12] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:858\u001b[24m\u001b[39m\n [13] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\n [14] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:861\u001b[24m\u001b[39m\n [15] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n [16] \u001b[0m\u001b[1mdeserialize_msg\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mmessages.jl:87\u001b[24m\u001b[39m\n [17] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:716\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n [18] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:714\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n [19] \u001b[0m\u001b[1mmessage_handler_loop\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:169\u001b[24m\u001b[39m\n [20] \u001b[0m\u001b[1mprocess_tcp_streams\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:126\u001b[24m\u001b[39m\n [21] \u001b[0m\u001b[1m#103\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:429\u001b[24m\u001b[39m",
     "output_type": "error",
     "traceback": [
      "On worker 9:\nUndefVarError: #complicated_calculation not defined\nStacktrace:\n  [1] \u001b[0m\u001b[1mdeserialize_datatype\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:1332\u001b[24m\u001b[39m\n  [2] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:854\u001b[24m\u001b[39m\n  [3] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\n  [4] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:861\u001b[24m\u001b[39m\n  [5] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [6] \u001b[0m\u001b[1mdeserialize_global_from_main\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mclusterserialize.jl:160\u001b[24m\u001b[39m\n  [7] \u001b[0m\u001b[1m#5\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mclusterserialize.jl:72\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n  [8] \u001b[0m\u001b[1mforeach\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2712\u001b[24m\u001b[39m\n  [9] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mclusterserialize.jl:72\u001b[24m\u001b[39m\n [10] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:947\u001b[24m\u001b[39m\n [11] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\n [12] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:858\u001b[24m\u001b[39m\n [13] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\n [14] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:861\u001b[24m\u001b[39m\n [15] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Serialization/src/\u001b[39m\u001b[90m\u001b[4mSerialization.jl:801\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n [16] \u001b[0m\u001b[1mdeserialize_msg\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mmessages.jl:87\u001b[24m\u001b[39m\n [17] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:716\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n [18] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4messentials.jl:714\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n [19] \u001b[0m\u001b[1mmessage_handler_loop\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:169\u001b[24m\u001b[39m\n [20] \u001b[0m\u001b[1mprocess_tcp_streams\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/\u001b[39m\u001b[90m\u001b[4mprocess_messages.jl:126\u001b[24m\u001b[39m\n [21] \u001b[0m\u001b[1m#103\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:429\u001b[24m\u001b[39m",
      "",
      "Stacktrace:",
      " [1] remotecall_fetch(::Function, ::Distributed.Worker; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ Distributed /opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/remotecall.jl:469",
      " [2] remotecall_fetch(::Function, ::Distributed.Worker)",
      "   @ Distributed /opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/remotecall.jl:461",
      " [3] remotecall_fetch(::Function, ::Int64; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ Distributed /opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/remotecall.jl:496",
      " [4] remotecall_fetch(::Function, ::Int64)",
      "   @ Distributed /opt/julia-1.7.3/share/julia/stdlib/v1.7/Distributed/src/remotecall.jl:496",
      " [5] top-level scope",
      "   @ In[30]:8",
      " [6] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "function complicated_calculation()\n",
    "    sleep(1) # so complex that it takes a long time :)\n",
    "    randexp(5)\n",
    "end\n",
    "\n",
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think of every worker as a separate Julia instance.**\n",
    "\n",
    "We only defined `complicated_calculation()` on the master process. The function doesn't exist on any of the workers yet.\n",
    "\n",
    "The macro `@everywhere` comes for the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin # execute this block on all workers\n",
    "    using Random\n",
    "    \n",
    "    function complicated_calculation()\n",
    "        sleep(1)\n",
    "        randexp(5) # lives in Random\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 0.38745762810154094\n",
       " 3.153131732886896\n",
       " 0.26071378350653146\n",
       " 1.3529543484048359\n",
       " 1.148318031667005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a crucial difference between the following two pieces of code. Can you guess what it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method1 (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method1()\n",
    "    A = rand(100,100)\n",
    "    B = rand(100,100)\n",
    "    C = @fetch A^2 * B^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method2 (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method2()\n",
    "    C = @fetch rand(100,100)^2 * rand(100,100)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  347.738 μs (90 allocations: 237.80 KiB)\n",
      "  294.214 μs (68 allocations: 80.94 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime method1();\n",
    "@btime method2();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 is slower, because `A` and `B` are created on the master process, transferred to a worker, and squared and multiplied on the worker process before the result is finally transferred back to the master.\n",
    "\n",
    "Method 2, on the other hand, creates, squares, and multiplies the random matrix all on the work process and only submits the result to the master.\n",
    "\n",
    "Hence, `method1` is **transferring 3x as much data** between the master and the worker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data movement is crucial!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example, it's rather easy to identify the faster method.\n",
    "\n",
    "In a real program, however, understanding data movement does require more thought and likely some measurement.\n",
    "\n",
    "For example, if the first process needs matrix `A` in a follow-up computation then the first method might be better in this case. Or, if computing `A` is expensive and only the current process has it, then moving it to another process might be unavoidable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer latency at a human scale\n",
    "\n",
    "To understand why thinking about data is important it's instructive to look at the time scales involved in data access.\n",
    "\n",
    "<img src=\"imgs/latency_human_scales.png\" width=900px>\n",
    "\n",
    "(taken from https://www.prowesscorp.com/computer-latency-at-a-human-scale/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid globals (once more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myglobal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whohas (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function whohas(s::String)\n",
    "    @everywhere begin\n",
    "        var = Symbol($s)\n",
    "        if isdefined(Main, var)\n",
    "            println(\"$var exists.\")\n",
    "        else\n",
    "            println(\"Doesn't exist.\")\n",
    "        end\n",
    "    end\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 6:\tDoesn't exist.\n",
      "      From worker 9:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetchfrom 6 myglobal+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 6:\tmyglobal exists.\n",
      "      From worker 9:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals get copied to workers and continue to exist as globals even after the call.\n",
    "\n",
    "This could lead to memory accumulation if many globals are used (just as it would in a single Julia session).\n",
    "\n",
    "It's better to avoid them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there exist tools for **explicit data transfer** beyond what we discuss here: see [`Channel`s and `RemoteChannel`s](https://docs.julialang.org/en/v1/manual/distributed-computing/#Channels-and-RemoteChannels) as well as [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing the easy way - `@distributed` and `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen the build block of commands for distributed computing in Julia. Having scientific computing in mind, one might not always want to think about how to distribute the work and explicitly spawn tasks.\n",
    "\n",
    "Also, fortunately, many useful parallel computations do not require (much) data movement. A common example is a direct Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. (We'll get to that later!)\n",
    "\n",
    "Julia provides convenience macros to\n",
    " * Parallelize loops (`@distributed`)\n",
    " * Apply a function to all elements in some collection (`pmap`)\n",
    " \n",
    "Let's explore these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed loops (`@distributed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  264.686 ms (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "# serial version - count heads in a series of coin tosses\n",
    "function add_serial(n)\n",
    "    c = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "@btime add_serial(200_000_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is trivially parallelizable since the loop iterations are independent of each other. We can distribute coin tosses over a couple of workers.\n",
    "\n",
    "Afterwards we combine the results, that is we sum them up. The combination process is generally called a *reduction*, and in this case `sum` is the *reducer function*.\n",
    "\n",
    "To distribute the for loop over worker processes Julia provides the `@distributed` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@distributed\n",
       "\\end{verbatim}\n",
       "A distributed memory, parallel for loop of the form :\n",
       "\n",
       "\\begin{verbatim}\n",
       "@distributed [reducer] for var = range\n",
       "    body\n",
       "end\n",
       "\\end{verbatim}\n",
       "The specified range is partitioned and locally executed across all workers. In case an optional reducer function is specified, \\texttt{@distributed} performs local reductions on each worker with a final reduction on the calling process.\n",
       "\n",
       "Note that without a reducer function, \\texttt{@distributed} executes asynchronously, i.e. it spawns independent tasks on all available workers and returns immediately without waiting for completion. To wait for completion, prefix the call with \\href{@ref}{\\texttt{@sync}}, like :\n",
       "\n",
       "\\begin{verbatim}\n",
       "@sync @distributed for var = range\n",
       "    body\n",
       "end\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "@distributed\n",
       "```\n",
       "\n",
       "A distributed memory, parallel for loop of the form :\n",
       "\n",
       "```\n",
       "@distributed [reducer] for var = range\n",
       "    body\n",
       "end\n",
       "```\n",
       "\n",
       "The specified range is partitioned and locally executed across all workers. In case an optional reducer function is specified, `@distributed` performs local reductions on each worker with a final reduction on the calling process.\n",
       "\n",
       "Note that without a reducer function, `@distributed` executes asynchronously, i.e. it spawns independent tasks on all available workers and returns immediately without waiting for completion. To wait for completion, prefix the call with [`@sync`](@ref), like :\n",
       "\n",
       "```\n",
       "@sync @distributed for var = range\n",
       "    body\n",
       "end\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  @distributed\u001b[39m\n",
       "\n",
       "  A distributed memory, parallel for loop of the form :\n",
       "\n",
       "\u001b[36m  @distributed [reducer] for var = range\u001b[39m\n",
       "\u001b[36m      body\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\n",
       "  The specified range is partitioned and locally executed across all workers.\n",
       "  In case an optional reducer function is specified, \u001b[36m@distributed\u001b[39m performs\n",
       "  local reductions on each worker with a final reduction on the calling\n",
       "  process.\n",
       "\n",
       "  Note that without a reducer function, \u001b[36m@distributed\u001b[39m executes asynchronously,\n",
       "  i.e. it spawns independent tasks on all available workers and returns\n",
       "  immediately without waiting for completion. To wait for completion, prefix\n",
       "  the call with \u001b[36m@sync\u001b[39m, like :\n",
       "\n",
       "\u001b[36m  @sync @distributed for var = range\u001b[39m\n",
       "\u001b[36m      body\u001b[39m\n",
       "\u001b[36m  end\u001b[39m"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  69.952 ms (285 allocations: 12.19 KiB)\n"
     ]
    }
   ],
   "source": [
    "# distributed version\n",
    "function add_distributed(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        Int(rand(Bool))\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "@btime add_distributed(200_000_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed version is about **4x faster**, which is all we could hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see who is doing the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 10:\t0\n",
      "      From worker 10:\t0\n",
      "      From worker 12:\t1\n",
      "      From worker 12:\t0\n",
      "      From worker 11:\t0\n",
      "      From worker 11:\t0\n",
      "      From worker 13:\t0\n",
      "      From worker 13:\t0\n"
     ]
    }
   ],
   "source": [
    "# verbose distributed version\n",
    "function add_distributed(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        x = Int(rand(Bool))\n",
    "        println(x);\n",
    "        x\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "add_distributed(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the work is evenly distributed between the workers. By using `@distributed` we let Julia decide how to split up the work and can't control it ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common mistake when using `@distributed` is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f(n)\n",
    "    a = 0\n",
    "    @distributed (+) for i in 1:n\n",
    "        a += 1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = f(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect the value of `a` to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (sort of) see what's happening by making everything global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 13:\t1\n",
      "      From worker 13:\t1\n",
      "      From worker 12:\t1\n",
      "      From worker 12:\t1\n",
      "      From worker 11:\t1\n",
      "      From worker 11:\t1\n",
      "      From worker 10:\t1\n",
      "      From worker 10:\t1\n",
      "      From worker 10:\t1\n",
      "      From worker 11:\t1\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "@distributed (+) for i in 1:10\n",
    "    println(\"1\")\n",
    "    global a += 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0\n",
      "      From worker 12:\ta = 2\n",
      "      From worker 13:\ta = 2\n",
      "      From worker 10:\ta = 3\n",
      "      From worker 11:\ta = 3\n"
     ]
    }
   ],
   "source": [
    "@everywhere @show a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `a` gets copied to the worker processes as it is referenced in the distributed loop. \n",
    "\n",
    "Every worker will then increment its copy of `a`.\n",
    "\n",
    "However, we do not save the result of the reduction (sum) but instead return `a` from the master process, which hasn't been altered at all.\n",
    "\n",
    "Corrected version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f2(n)\n",
    "    a = @distributed (+) for i in 1:n\n",
    "        1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = f2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I don't want to reduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the mistake above, the following example might not have the effect one expects. **Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x00007fb9be6a4b90"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 11:\ta = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0]\n",
      "      From worker 10:\ta = [0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 12:\ta = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0]\n",
      "      From worker 13:\ta = [1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "@everywhere @show a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `@distributed` without a reduction function returns a `Task`. It is basically a distributed version of `@spawn` for all the iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SharedArray`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually make all processes operate on the same array, one can use a `SharedArray`.\n",
    "\n",
    "Note that a `SharedArray` only works if the **processes live on the same host**.\n",
    "\n",
    "The constructor of a SharedArray is\n",
    "\n",
    "```julia\n",
    "SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])\n",
    "```\n",
    "\n",
    "which creates an `N`-dimensional shared array of a (bits) type `T` and size `dims` across the processes specified by `pids`.\n",
    "\n",
    "(If an `init` function, of signature `initfn(S::SharedArray)`, is specified, it is called on all the participating workers. You can specify that each worker runs the init function on a distinct portion of the array, thereby parallelizing initialization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays # must be loaded everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Matrix{Float64}:\n",
       " 0.814917  0.399215   0.757549\n",
       " 0.327237  0.0101991  0.463634"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 SharedMatrix{Float64}:\n",
       " 0.814917  0.399215   0.757549\n",
       " 0.327237  0.0101991  0.463634"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = SharedArray(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we know how to create and fill our `SharedArray` we can create a parallel fill function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 SharedMatrix{Float64}:\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Float64}(N,N)\n",
    "    @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "fill_shared_problematic(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why is the method in its current form problematic? Try to find out yourself by going to larger `N` and, for example, inspecting the minimum of the returned `SharedArray`!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to larger matrix sizes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "S = fill_shared_problematic(100)\n",
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how sometimes the array isn't completely filled but still contains zeros. This is because it isn't filled **yet**!\n",
    "\n",
    "Check again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` to synchronize our distributed for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @sync @distributed for i in 1:length(S) # added @sync here\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "S = fill_shared_problematic(100)\n",
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's **benchmark** this for a larger matrix size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.362492 seconds (159.72 k allocations: 771.511 MiB, 2.80% gc time, 12.86% compilation time)\n"
     ]
    }
   ],
   "source": [
    "# regular array\n",
    "function fill_regular(N)\n",
    "    A = Matrix{Int64}(undef,N,N)\n",
    "    for i in 1:length(A)\n",
    "        A[i] = i\n",
    "    end\n",
    "    A\n",
    "end\n",
    "\n",
    "@time fill_regular(10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.283145 seconds (64.91 k allocations: 3.404 MiB, 8.43% compilation time)\n"
     ]
    }
   ],
   "source": [
    "# shared array\n",
    "function fill_shared(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @sync @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "@time fill_shared(10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is of course just filling an array.\n",
    "\n",
    "If there were actual calculations it might actually be beneficial to distribute the work across workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel map: `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we merely wish to apply a function to all all elements in a collection.\n",
    "\n",
    "For those cases, Julia provides the `pmap` (parallel map) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we want to compute the singular values of a bunch of larger matrices in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(Hwloc.num_physical_cores()); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Vector{Float64}}:\n",
       " [99.99293829260455, 8.14270718951684, 7.874851756445166, 7.691537441242399, 7.59182815395129, 7.547977547044977, 7.457029647491173, 7.42705379885649, 7.313146065150273, 7.257923041798819  …  0.29463819423913773, 0.26365483923703453, 0.23008729614872356, 0.20735972013467208, 0.1711050106071252, 0.12833723398140268, 0.11816553998754241, 0.08733358684415295, 0.03811697250366554, 0.013788036739829639]\n",
       " [100.00973836349664, 8.053489472139887, 7.9327585906331, 7.700408444588085, 7.627554278476183, 7.519673453210566, 7.441948897361033, 7.384925681883303, 7.3493124449252685, 7.202099003846035  …  0.29121010771600014, 0.2691605146432276, 0.24776918867189124, 0.22985593868069532, 0.17640363294483952, 0.09064020130023769, 0.07130170295697844, 0.050473591783900755, 0.031689500777658954, 0.016760255444330633]\n",
       " [99.4946686239722, 8.069242335932826, 7.978405886374229, 7.907715093627776, 7.717744141579469, 7.646967507277287, 7.471231935423299, 7.426939859960157, 7.302395070243191, 7.214961430114752  …  0.31810864306633124, 0.31165153018195285, 0.25201327975760085, 0.22129192790818286, 0.15154184768964238, 0.1356606350219903, 0.09570573857273071, 0.08698773676182098, 0.011956225757524946, 0.003630033012814656]\n",
       " [100.3063881220093, 8.071744147714467, 7.894239348556211, 7.677489931938317, 7.6602601481247286, 7.568788958781773, 7.447081552166117, 7.389915930347709, 7.251361815004641, 7.209402375269853  …  0.32975869438838995, 0.327246516883035, 0.2695805419224103, 0.18507206593648556, 0.16959814228423098, 0.15105607079778305, 0.13748897386292258, 0.10341715587074556, 0.057194538623420395, 0.0038781959201747134]\n",
       " [99.70338444910821, 7.994130523414689, 7.984603423715167, 7.697341728062424, 7.690816199422599, 7.591343481109089, 7.517165046575112, 7.484540505764795, 7.3781105697218425, 7.272409619896623  …  0.28562918943419957, 0.2519471566232767, 0.241958362541711, 0.20305455312990459, 0.17473557534732018, 0.12901803138120616, 0.09436828746218046, 0.0785033609086405, 0.0272508654597258, 0.006672032510414677]\n",
       " [100.14762823970418, 7.923889356162098, 7.873179866024225, 7.764610646907408, 7.68432927181711, 7.600278534600663, 7.514251356690178, 7.402377160454438, 7.2770195472912835, 7.238789089803137  …  0.3155344690635475, 0.27079667382634964, 0.2606191188147763, 0.24288014356921858, 0.20354263201961362, 0.14133319374217343, 0.07360683573978306, 0.06270638451088001, 0.04874607884365145, 0.0315942160261468]\n",
       " [100.04247358097162, 8.075934537155499, 7.900565552868009, 7.8800081138759355, 7.614412615373577, 7.577068287826296, 7.464419695012635, 7.4002096624457465, 7.362456254968267, 7.290042113029279  …  0.24070307337369848, 0.2315157181230952, 0.20239591419558503, 0.18839428776737321, 0.157577473450867, 0.15204617889323768, 0.12471305973378716, 0.06279197872631226, 0.047967522522916306, 0.007605628922795185]\n",
       " [99.94727993849679, 8.01054347125135, 7.836712495268802, 7.7617119328940944, 7.6787586833492165, 7.588713431699604, 7.463511888167167, 7.422009738652253, 7.321139119905773, 7.262841727234902  …  0.31542835381425466, 0.2755315442043178, 0.2428214713978054, 0.24157696585211663, 0.19852814284036488, 0.17808101669986884, 0.13404238329815815, 0.07758255504137379, 0.03522148787922735, 0.008958980522737539]\n",
       " [100.05818753974204, 8.057403793192698, 7.900093142868057, 7.843796168508474, 7.6782866836610335, 7.554297699796714, 7.530909335714072, 7.407259970612743, 7.3374523151701725, 7.250949650877184  …  0.28368399715912623, 0.22910149178055875, 0.18319679254360544, 0.15726780185272096, 0.13476368010876272, 0.09617239115562833, 0.0742186977338938, 0.060170934536494636, 0.05304925845227814, 0.01244551411427173]\n",
       " [100.42325060461279, 8.156912292339804, 7.82927235079573, 7.7093407981417, 7.6345999689989705, 7.6075968172725315, 7.438376457778167, 7.361874416064995, 7.266996624107115, 7.197057714895054  …  0.28630243518302567, 0.24527960746326444, 0.24071529626179777, 0.23426581069683428, 0.14583714831379618, 0.1314218951678288, 0.09442503067305766, 0.07900945362510488, 0.02705702402937742, 0.01425577372678622]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];\n",
    "\n",
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 14:\t14\n",
      "      From worker 14:\t14\n",
      "      From worker 14:\t14\n",
      "      From worker 14:\t14\n",
      "      From worker 14:\t14\n",
      "      From worker 14:\t14\n",
      "      From worker 17:\t17\n",
      "      From worker 14:\t14\n",
      "      From worker 16:\t16\n",
      "      From worker 15:\t15\n"
     ]
    }
   ],
   "source": [
    "# Check that really all of the workers participated\n",
    "pmap(m->begin println(myid()); svdvals(m) end, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.108873 seconds (35.87 k allocations: 6.136 MiB, 53.20% compilation time)\n",
      "  0.125522 seconds (168.64 k allocations: 13.504 MiB, 59.00% compilation time)\n",
      "  0.021331 seconds (522 allocations: 37.688 KiB)\n"
     ]
    }
   ],
   "source": [
    "function svds_loop(M)\n",
    "    svds = Vector{Vector{Float64}}(undef, 10)\n",
    "    for (i, m) in enumerate(M)\n",
    "        svds[i] = svdvals(m)\n",
    "    end\n",
    "    svds\n",
    "end\n",
    "\n",
    "@time svds_loop(M);\n",
    "@time svdvals.(M);\n",
    "@time pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to choose which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's pmap is designed for the case where\n",
    "* each function call does a **large amount of work** and/or\n",
    "* the **workload is non-uniform**.\n",
    "\n",
    "In contrast, `@distributed` can handle situations where\n",
    "* **each iteration is tiny**, i.e. perhaps only summing two numbers and/or\n",
    "* each iteration **takes about the same time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling things up: distributed computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked on multiple cores on a single machine, your laptop for example.\n",
    "\n",
    "Processes can live on other machines as well! This allows us to distribute our computation across computer clusters.\n",
    "\n",
    "In principle, the plan of action is the same as in the multi-core case. However, we have to take into account the different memory situation. In particular, **data movement is expensive** and we won't be able to use `SharedArray`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00007fb981fc7de0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers()) # fresh start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating workers on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding processes on different machines is not much harder than adding them on your local machine. In the following we will take the last example, calculating singular values of a bunch of matrices, and distribute it over multiple computers in our thp network.\n",
    "\n",
    "In Julia, starting worker processes is handled by [ClusterManagers](https://docs.julialang.org/en/stable/manual/parallel-computing/#ClusterManagers-1).\n",
    "\n",
    "* The default one is `LocalManager`. It is automatically used when running `addprocs(i::Integer)` and we have implicitly used it already!\n",
    "* The one we are going to use for the THP cluster is `SSHManager`. It is automatically used when running `addprocs(hostnames::Array)`.\n",
    "\n",
    "Other cluster managers for SLURM, PBS, and others are provided in [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, starting processes on other computers can be done by `addprocs([\"l93\", \"l94\"])`, where `\"l93\"` and `\"l94\"` are hostnames. The only requirement is a **passwordless ssh access** to all specified hosts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Demonstrate in terminal from thp node*\n",
    "\n",
    "```julia\n",
    "using Distributed\n",
    "\n",
    "addprocs([\"l93\", \"l94\"])\n",
    "\n",
    "@everywhere println(gethostname())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also start multiple processes on different machines:\n",
    "```julia\n",
    "addprocs([(\"l93\", 2), (\"l94\", 3)]) # starts 2 workers on l92 and 3 workers on l93\n",
    "\n",
    "# Use :auto to start as many processes as CPUs are available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `addprocs` expects the julia executable in the same folder as on the master computer (remember: workers are independent Julia processes). It will also try to `cd` to the same folder.\n",
    "\n",
    "In my case this would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show pwd();\n",
    "@show Sys.BINDIR;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both folders don't exist in my thp account (those are linux machines!), so I'll have to tell Julia to use different paths.\n",
    "\n",
    "Also, as per thp cluster guidelines one **(!) must (!) run computations on other thp computer with `nice -19` priority setting**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating `nice -19` workers and specifying directories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from `?addprocs`, `addprocs` takes a bunch of keyword arguments, two of which are of particular importance.\n",
    "\n",
    "* `dir`: working directory of the worker process\n",
    "* `exename`: path to julia executable (potentially augmented with pre-commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (exename=`nice -19 /home/bauer/bin/julia-1.5.3/bin/julia --project=/home/bauer/JuliaNRW21`, dir=\"/home/bauer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs([(\"l93\", :auto)]; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere println(gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get some resources :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machines = [\"l93\", \"l94\", \"l96\"];\n",
    "\n",
    "procs_per_machine = :auto; # :auto for n = # cpus\n",
    "\n",
    "jobs = [(m,procs_per_machine) for m in machines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(jobs; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere println(gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@time x = pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed arrays (`DArray`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github: https://github.com/JuliaParallel/DistributedArrays.jl\n",
    "\n",
    "In a `DArray`, each process has local access to just a chunk of the data, and no two processes share the same chunk. Processes can be on different hosts.\n",
    "\n",
    "Distributed arrays are for example useful if\n",
    "\n",
    "* Expensive calculations should be performed in parallel on parts of the array on different hosts.\n",
    "* The data doesn't fit into the local machines memory (Loading big files in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = distribute(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which workers hold parts of D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parts do they hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localpart(D) # the master doesn't hold anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which parts do they hold?\n",
    "for p in workers()\n",
    "    display(@fetchfrom p localpart(D))\n",
    "    display(@fetchfrom p DistributedArrays.localindices(D)) # DistributedArrays. necessary because of SharedArrays above\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Msquared = map(svdvals, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Dsquared = map(svdvals, D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time Psquared = pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Msquared ≈ Dsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsquared ≈ Psquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember, for small operations the data movement can (and will) exceed the benefit of parallelizing the computation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time map(sum, M);\n",
    "@time map(sum, D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop worker processes!\n",
    "rmprocs(workers())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
